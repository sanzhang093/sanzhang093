# -*- coding: utf-8 -*-
"""
AI ç«äº‰å¯¹æ‰‹æ™ºèƒ½åˆ†æä»£ç†å›¢é˜Ÿ - ç»¼åˆç‰ˆæœ¬
åŠŸèƒ½ï¼šç»“åˆ OpenAI å’Œ Qwen æ¨¡å‹ï¼Œæä¾›å¤šç§åˆ†æé€‰é¡¹
"""

import streamlit as st
import requests
import pandas as pd
import json
from typing import List, Optional, Dict, Any
from pydantic import BaseModel, Field
import time

# å°è¯•å¯¼å…¥å„ç§ä¾èµ–
try:
    from agno.agent import Agent
    from agno.tools.firecrawl import FirecrawlTools
    from agno.models.openai import OpenAIChat
    from agno.tools.duckduckgo import DuckDuckGoTools
    AGNO_AVAILABLE = True
except ImportError:
    AGNO_AVAILABLE = False

try:
    from qwen_agent.agents import Assistant
    from qwen_agent.llm import get_chat_model
    QWEN_AVAILABLE = True
except ImportError:
    QWEN_AVAILABLE = False

try:
    from firecrawl import FirecrawlApp
    FIRECRAWL_AVAILABLE = True
except ImportError:
    FIRECRAWL_AVAILABLE = False

try:
    from exa_py import Exa
    EXA_AVAILABLE = True
except ImportError:
    EXA_AVAILABLE = False

# é…ç½® Streamlit é¡µé¢
st.set_page_config(page_title="AI ç«äº‰å¯¹æ‰‹æ™ºèƒ½åˆ†æä»£ç†å›¢é˜Ÿ - ç»¼åˆç‰ˆæœ¬", layout="wide")

# æ·»åŠ è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.5rem;
        font-weight: bold;
        color: #2e8b57;
        margin-top: 2rem;
        margin-bottom: 1rem;
        border-bottom: 2px solid #2e8b57;
        padding-bottom: 0.5rem;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .info-box {
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
    .competitor-card {
        background-color: #f8f9fa;
        border: 1px solid #dee2e6;
        border-radius: 0.5rem;
        padding: 1rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ä¸»ç•Œé¢æ ‡é¢˜
st.markdown('<h1 class="main-header">ğŸ§² AI ç«äº‰å¯¹æ‰‹æ™ºèƒ½åˆ†æä»£ç†å›¢é˜Ÿ</h1>', unsafe_allow_html=True)
st.markdown('<h2 style="text-align: center; color: #666; margin-bottom: 2rem;">ç»¼åˆç‰ˆæœ¬ - æ”¯æŒå¤šç§AIæ¨¡å‹</h2>', unsafe_allow_html=True)

# ä¾§è¾¹æ  - æ¨¡å‹å’ŒAPIé…ç½®
st.sidebar.title("ğŸ”§ é…ç½®é€‰é¡¹")

# å®‰å…¨æç¤º
st.sidebar.markdown("""
<div class="warning-box">
    <h4>ğŸ”’ å®‰å…¨æç¤º</h4>
    <p><strong>é‡è¦ï¼š</strong>è¯·å‹¿å°†APIå¯†é’¥æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿï¼</p>
    <p>å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶æ¥ç®¡ç†APIå¯†é’¥ã€‚</p>
</div>
""", unsafe_allow_html=True)

# æ¨¡å‹é€‰æ‹©
model_provider = st.sidebar.selectbox(
    "é€‰æ‹©AIæ¨¡å‹æä¾›å•†",
    options=["OpenAI GPT-4", "Qwen (é€šä¹‰åƒé—®)"],
    help="é€‰æ‹©ç”¨äºåˆ†æçš„AIæ¨¡å‹"
)

# æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æ˜¾ç¤ºç›¸åº”çš„é…ç½®
if model_provider == "OpenAI GPT-4":
    st.sidebar.subheader("OpenAI é…ç½®")
    openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password", help="OpenAI API å¯†é’¥")
    
    if openai_api_key:
        st.session_state.openai_api_key = openai_api_key
        st.session_state.model_provider = "openai"
        st.sidebar.success("âœ… OpenAI API å·²é…ç½®")
    else:
        st.sidebar.warning("âš ï¸ è¯·è¾“å…¥ OpenAI API Key")
        
else:  # Qwen
    st.sidebar.subheader("Qwen é…ç½®")
    # DashScope API Key
    dashscope_api_key = st.sidebar.text_input("DashScope API Key", type="password", help="é˜¿é‡Œäº‘ DashScope API å¯†é’¥")
    qwen_model = st.sidebar.selectbox(
        "é€‰æ‹© Qwen æ¨¡å‹",
        options=["qwen-max", "qwen-plus", "qwen-turbo", "qwen-long"],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„ Qwen æ¨¡å‹"
    )
    
    if dashscope_api_key:
        st.session_state.dashscope_api_key = dashscope_api_key
        st.session_state.qwen_model = qwen_model
        st.session_state.model_provider = "qwen"
        st.sidebar.success("âœ… Qwen API å·²é…ç½®")
    else:
        st.sidebar.warning("âš ï¸ è¯·è¾“å…¥ DashScope API Key")

# æœç´¢å¼•æ“é€‰æ‹©
st.sidebar.subheader("ğŸ” æœç´¢å¼•æ“é…ç½®")
search_engine = st.sidebar.selectbox(
    "é€‰æ‹©æœç´¢å¼•æ“",
    options=["Perplexity AI - Sonar Pro", "Exa AI"],
    help="é€‰æ‹©ç”¨äºæŸ¥æ‰¾ç«äº‰å¯¹æ‰‹çš„æœç´¢å¼•æ“"
)

# æ ¹æ®é€‰æ‹©çš„æœç´¢å¼•æ“æ˜¾ç¤ºç›¸åº”çš„APIå¯†é’¥è¾“å…¥æ¡†
if search_engine == "Perplexity AI - Sonar Pro":
    perplexity_api_key = st.sidebar.text_input("Perplexity API Key", type="password", help="Perplexity API å¯†é’¥")
    if perplexity_api_key:
        st.session_state.perplexity_api_key = perplexity_api_key
        st.session_state.search_engine = "perplexity"
        st.sidebar.success("âœ… Perplexity API å·²é…ç½®")
    else:
        st.sidebar.warning("âš ï¸ è¯·è¾“å…¥ Perplexity API Key")
else:  # Exa AI
    # Exa API Key
    exa_api_key = st.sidebar.text_input("Exa API Key", type="password", help="Exa API å¯†é’¥")
    if exa_api_key:
        st.session_state.exa_api_key = exa_api_key
        st.session_state.search_engine = "exa"
        st.sidebar.success("âœ… Exa API å·²é…ç½®")
    else:
        st.sidebar.warning("âš ï¸ è¯·è¾“å…¥ Exa API Key")

# Firecrawl é…ç½®
st.sidebar.subheader("ğŸ•·ï¸ ç½‘ç«™çˆ¬å–é…ç½®")
# Firecrawl API Key
firecrawl_api_key = st.sidebar.text_input("Firecrawl API Key", type="password", help="Firecrawl API å¯†é’¥")
if firecrawl_api_key:
    st.session_state.firecrawl_api_key = firecrawl_api_key
    st.sidebar.success("âœ… Firecrawl API å·²é…ç½®")
else:
    st.sidebar.warning("âš ï¸ è¯·è¾“å…¥ Firecrawl API Key")

# åŠŸèƒ½è¯´æ˜
st.markdown("""
<div class="info-box">
    <h4>ğŸš€ åŠŸèƒ½ç‰¹ç‚¹</h4>
    <ul>
        <li><strong>å¤šæ¨¡å‹æ”¯æŒ</strong>: æ”¯æŒ OpenAI GPT-4 å’Œ Qwen (é€šä¹‰åƒé—®)</li>
        <li><strong>æ™ºèƒ½æœç´¢å¼•æ“</strong>: æ”¯æŒ Perplexity AI å’Œ Exa AI</li>
        <li><strong>ä¸“ä¸šçˆ¬å–</strong>: ä½¿ç”¨ Firecrawl æå–é«˜è´¨é‡ç½‘ç«™æ•°æ®</li>
        <li><strong>æ·±åº¦åˆ†æ</strong>: ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šå’Œå¯¹æ¯”è¡¨æ ¼</li>
        <li><strong>é”™è¯¯å¤„ç†</strong>: æ™ºèƒ½é”™è¯¯å¤„ç†å’Œå¤‡ç”¨æ–¹æ¡ˆ</li>
    </ul>
    <p><strong>ä½¿ç”¨æ–¹æ³•ï¼š</strong> é…ç½®APIå¯†é’¥åï¼Œæä¾›æ‚¨å…¬å¸çš„ <strong>URL</strong> æˆ– <strong>æè¿°</strong>ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨åˆ†æç«äº‰å¯¹æ‰‹ã€‚</p>
</div>
""", unsafe_allow_html=True)

# ç”¨æˆ·è¾“å…¥åŒºåŸŸ
st.subheader("ğŸ“ è¾“å…¥ä¿¡æ¯")
col1, col2 = st.columns(2)
with col1:
    url = st.text_input("è¾“å…¥æ‚¨çš„å…¬å¸ URLï¼š", placeholder="https://example.com")
with col2:
    description = st.text_area("è¾“å…¥æ‚¨å…¬å¸çš„æè¿°ï¼ˆå¦‚æœ URL ä¸å¯ç”¨ï¼‰ï¼š", placeholder="ä¾‹å¦‚ï¼šAIé©±åŠ¨çš„æ•°æ®åˆ†æå¹³å°")

# ç«äº‰å¯¹æ‰‹æ•°æ®æ¨¡å¼å®šä¹‰
class CompetitorDataSchema(BaseModel):
    """ç«äº‰å¯¹æ‰‹æ•°æ®æ¨¡å¼"""
    company_name: str = Field(description="å…¬å¸åç§°")
    pricing: str = Field(description="å®šä»·è¯¦æƒ…ã€å±‚çº§å’Œè®¡åˆ’")
    key_features: List[str] = Field(description="äº§å“/æœåŠ¡çš„ä¸»è¦åŠŸèƒ½å’Œèƒ½åŠ›")
    tech_stack: List[str] = Field(description="ä½¿ç”¨çš„æŠ€æœ¯ã€æ¡†æ¶å’Œå·¥å…·")
    marketing_focus: str = Field(description="ä¸»è¦è¥é”€è§’åº¦å’Œç›®æ ‡å—ä¼—")
    customer_feedback: str = Field(description="å®¢æˆ·æ¨èã€è¯„è®ºå’Œåé¦ˆ")

# OpenAI åˆ†æå™¨
class OpenAIAnalyzer:
    """ä½¿ç”¨ OpenAI çš„ç«äº‰å¯¹æ‰‹åˆ†æå™¨"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        if AGNO_AVAILABLE:
            self.analysis_agent = Agent(
                model=OpenAIChat(id="gpt-4o", api_key=api_key),
                show_tool_calls=True,
                markdown=True
            )
        else:
            self.analysis_agent = None
    
    def analyze_competitors(self, competitor_data: List[Dict]) -> str:
        """åˆ†æç«äº‰å¯¹æ‰‹æ•°æ®"""
        if not self.analysis_agent:
            return "OpenAI Agent æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ agno åº“æ˜¯å¦æ­£ç¡®å®‰è£…"
        
        # æ ¼å¼åŒ–æ•°æ®
        formatted_data = json.dumps(competitor_data, indent=2, ensure_ascii=False)
        
        # æ„å»ºåˆ†ææç¤º
        analysis_prompt = f"""
        è¯·åˆ†æä»¥ä¸‹ç«äº‰å¯¹æ‰‹æ•°æ®ï¼Œå¹¶æä¾›è¯¦ç»†çš„ç«äº‰åˆ†ææŠ¥å‘Šï¼š

        {formatted_data}

        è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
        1. å¸‚åœºå®šä½åˆ†æ - åˆ†æå„ç«äº‰å¯¹æ‰‹çš„å¸‚åœºå®šä½å’Œå·®å¼‚åŒ–ç­–ç•¥
        2. äº§å“åŠŸèƒ½å¯¹æ¯” - å¯¹æ¯”å„ç«äº‰å¯¹æ‰‹çš„æ ¸å¿ƒåŠŸèƒ½å’Œç‰¹æ€§
        3. å®šä»·ç­–ç•¥åˆ†æ - åˆ†æå®šä»·æ¨¡å¼å’Œç­–ç•¥
        4. æŠ€æœ¯æ ˆå¯¹æ¯” - åˆ†æå„ç«äº‰å¯¹æ‰‹ä½¿ç”¨çš„æŠ€æœ¯
        5. è¥é”€ç­–ç•¥åˆ†æ - åˆ†æç›®æ ‡å—ä¼—å’Œè¥é”€é‡ç‚¹
        6. ç«äº‰ä¼˜åŠ¿è¯†åˆ« - è¯†åˆ«å„ç«äº‰å¯¹æ‰‹çš„ç‹¬ç‰¹ä¼˜åŠ¿
        7. å¸‚åœºæœºä¼šå‘ç° - å‘ç°å¸‚åœºç©ºç™½å’Œæœºä¼š
        8. æˆ˜ç•¥å»ºè®® - æä¾›å…·ä½“çš„ç«äº‰ç­–ç•¥å»ºè®®

        è¯·æä¾›å…·ä½“ã€å¯æ“ä½œçš„åˆ†æç»“æœï¼Œé‡ç‚¹å…³æ³¨å¦‚ä½•è·å¾—ç«äº‰ä¼˜åŠ¿ã€‚
        è¯·ç¡®ä¿æŠ¥å‘Šå†…å®¹å®Œæ•´ä¸”ä¸é‡å¤ã€‚
        """
        
        try:
            report = self.analysis_agent.run(analysis_prompt)
            content = report.content
            
            # å¦‚æœå“åº”å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œè¿”å›å¤‡ç”¨åˆ†æ
            if len(content.strip()) < 100:
                return self._generate_fallback_analysis(competitor_data)
            
            return content
        except Exception as e:
            return f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
    
    def _generate_fallback_analysis(self, competitor_data: List[Dict]) -> str:
        """ç”Ÿæˆå¤‡ç”¨åˆ†ææŠ¥å‘Š"""
        if not competitor_data:
            return "æ²¡æœ‰ç«äº‰å¯¹æ‰‹æ•°æ®å¯ä¾›åˆ†æ"
        
        analysis = f"""
# ç«äº‰å¯¹æ‰‹åˆ†ææŠ¥å‘Šï¼ˆOpenAI å¤‡ç”¨ç‰ˆæœ¬ï¼‰

## åˆ†ææ¦‚è§ˆ
æˆåŠŸåˆ†æäº† {len(competitor_data)} ä¸ªç«äº‰å¯¹æ‰‹çš„æ•°æ®ã€‚

## ç«äº‰å¯¹æ‰‹åˆ—è¡¨
"""
        
        for i, competitor in enumerate(competitor_data, 1):
            analysis += f"""
### {i}. {competitor.get('company_name', f'ç«äº‰å¯¹æ‰‹ {i}')}
- **ç½‘ç«™**: {competitor.get('competitor_url', 'N/A')}
- **å®šä»·ç­–ç•¥**: {competitor.get('pricing', 'N/A')[:200]}...
- **å…³é”®åŠŸèƒ½**: {', '.join(competitor.get('key_features', [])[:3]) if competitor.get('key_features') else 'N/A'}
- **æŠ€æœ¯æ ˆ**: {', '.join(competitor.get('tech_stack', [])[:3]) if competitor.get('tech_stack') else 'N/A'}
- **è¥é”€é‡ç‚¹**: {competitor.get('marketing_focus', 'N/A')[:200]}...

"""
        
        analysis += """
## åŸºç¡€åˆ†æå»ºè®®

### 1. å¸‚åœºå®šä½åˆ†æ
- åˆ†æå„ç«äº‰å¯¹æ‰‹çš„å¸‚åœºå®šä½å’Œå·®å¼‚åŒ–ç­–ç•¥
- è¯†åˆ«å¸‚åœºç©ºç™½å’Œæœºä¼š

### 2. äº§å“åŠŸèƒ½å¯¹æ¯”
- å¯¹æ¯”å„ç«äº‰å¯¹æ‰‹çš„æ ¸å¿ƒåŠŸèƒ½å’Œç‰¹æ€§
- å‘ç°åŠŸèƒ½ä¼˜åŠ¿å’Œä¸è¶³

### 3. å®šä»·ç­–ç•¥åˆ†æ
- åˆ†æå®šä»·æ¨¡å¼å’Œç­–ç•¥
- åˆ¶å®šæœ‰ç«äº‰åŠ›çš„å®šä»·æ–¹æ¡ˆ

### 4. æŠ€æœ¯æ ˆå¯¹æ¯”
- åˆ†æå„ç«äº‰å¯¹æ‰‹ä½¿ç”¨çš„æŠ€æœ¯
- è¯„ä¼°æŠ€æœ¯ä¼˜åŠ¿å’ŒåŠ£åŠ¿

### 5. è¥é”€ç­–ç•¥åˆ†æ
- åˆ†æç›®æ ‡å—ä¼—å’Œè¥é”€é‡ç‚¹
- åˆ¶å®šå·®å¼‚åŒ–è¥é”€ç­–ç•¥

## å»ºè®®
1. æ·±å…¥åˆ†æç«äº‰å¯¹æ‰‹çš„ä¼˜åŠ£åŠ¿
2. åˆ¶å®šå·®å¼‚åŒ–ç«äº‰ç­–ç•¥
3. å…³æ³¨å¸‚åœºè¶‹åŠ¿å’Œå®¢æˆ·éœ€æ±‚
4. æŒç»­ç›‘æ§ç«äº‰å¯¹æ‰‹åŠ¨æ€

---
*æ³¨ï¼šæ­¤ä¸ºå¤‡ç”¨åˆ†ææŠ¥å‘Šï¼Œå»ºè®®æ£€æŸ¥OpenAI APIé…ç½®ä»¥è·å¾—æ›´æ·±å…¥çš„åˆ†æã€‚*
"""
        
        return analysis

# Qwen åˆ†æå™¨
class QwenAnalyzer:
    """ä½¿ç”¨ Qwen çš„ç«äº‰å¯¹æ‰‹åˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str):
        self.api_key = api_key
        self.model = model
        self.llm_cfg = {
            'model': model,
            'model_type': 'qwen_dashscope',
            'api_key': api_key,
            'generate_cfg': {
                'top_p': 0.8,
                'temperature': 0.7
            }
        }
        
        # åˆå§‹åŒ– Qwen Agent
        if QWEN_AVAILABLE:
            self.assistant = Assistant(
                llm=self.llm_cfg,
                system_message="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç«äº‰å¯¹æ‰‹åˆ†æä¸“å®¶ã€‚è¯·æ ¹æ®æä¾›çš„ä¿¡æ¯è¿›è¡Œæ·±å…¥åˆ†æï¼Œæä¾›å…·ä½“ã€å¯æ“ä½œçš„å»ºè®®ã€‚",
                function_list=[]
            )
        else:
            self.assistant = None
    
    def analyze_competitors(self, competitor_data: List[Dict]) -> str:
        """åˆ†æç«äº‰å¯¹æ‰‹æ•°æ®"""
        if not self.assistant:
            return "Qwen Agent æœªæ­£ç¡®åˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ qwen-agent åº“æ˜¯å¦æ­£ç¡®å®‰è£…"
        
        # æ ¼å¼åŒ–æ•°æ®
        formatted_data = json.dumps(competitor_data, indent=2, ensure_ascii=False)
        
        # æ„å»ºåˆ†ææç¤º
        analysis_prompt = f"""
        è¯·åˆ†æä»¥ä¸‹ç«äº‰å¯¹æ‰‹æ•°æ®ï¼Œå¹¶æä¾›è¯¦ç»†çš„ç«äº‰åˆ†ææŠ¥å‘Šï¼š

        {formatted_data}

        è¯·ä»ä»¥ä¸‹è§’åº¦è¿›è¡Œåˆ†æï¼š
        1. å¸‚åœºå®šä½åˆ†æ - åˆ†æå„ç«äº‰å¯¹æ‰‹çš„å¸‚åœºå®šä½å’Œå·®å¼‚åŒ–ç­–ç•¥
        2. äº§å“åŠŸèƒ½å¯¹æ¯” - å¯¹æ¯”å„ç«äº‰å¯¹æ‰‹çš„æ ¸å¿ƒåŠŸèƒ½å’Œç‰¹æ€§
        3. å®šä»·ç­–ç•¥åˆ†æ - åˆ†æå®šä»·æ¨¡å¼å’Œç­–ç•¥
        4. æŠ€æœ¯æ ˆå¯¹æ¯” - åˆ†æå„ç«äº‰å¯¹æ‰‹ä½¿ç”¨çš„æŠ€æœ¯
        5. è¥é”€ç­–ç•¥åˆ†æ - åˆ†æç›®æ ‡å—ä¼—å’Œè¥é”€é‡ç‚¹
        6. ç«äº‰ä¼˜åŠ¿è¯†åˆ« - è¯†åˆ«å„ç«äº‰å¯¹æ‰‹çš„ç‹¬ç‰¹ä¼˜åŠ¿
        7. å¸‚åœºæœºä¼šå‘ç° - å‘ç°å¸‚åœºç©ºç™½å’Œæœºä¼š
        8. æˆ˜ç•¥å»ºè®® - æä¾›å…·ä½“çš„ç«äº‰ç­–ç•¥å»ºè®®

        è¯·æä¾›å…·ä½“ã€å¯æ“ä½œçš„åˆ†æç»“æœï¼Œé‡ç‚¹å…³æ³¨å¦‚ä½•è·å¾—ç«äº‰ä¼˜åŠ¿ã€‚
        è¯·ç¡®ä¿æŠ¥å‘Šå†…å®¹å®Œæ•´ä¸”ä¸é‡å¤ã€‚
        """
        
        try:
            messages = [{'role': 'user', 'content': analysis_prompt}]
            response_content = ""
            seen_content = set()  # ç”¨äºå»é‡
            last_content_length = 0  # è®°å½•ä¸Šæ¬¡å†…å®¹é•¿åº¦
            
            # å¤„ç†Qwen Agentçš„æµå¼å“åº”
            for response in self.assistant.run(messages=messages):
                # æ£€æŸ¥å“åº”ç±»å‹å¹¶æå–å†…å®¹
                if isinstance(response, list):
                    for item in response:
                        if isinstance(item, dict):
                            if 'content' in item:
                                content = item['content']
                                # æ£€æŸ¥å†…å®¹æ˜¯å¦çœŸæ­£æ–°å¢ï¼ˆé¿å…é‡å¤çš„æ ‡é¢˜å’Œå¼€å¤´ï¼‰
                                if content and len(content) > last_content_length:
                                    new_content = content[last_content_length:]
                                    if new_content not in seen_content and len(new_content.strip()) > 0:
                                        response_content += new_content
                                        seen_content.add(new_content)
                                        last_content_length = len(content)
                            elif 'extra' in item and 'model_service_info' in item['extra']:
                                model_info = item['extra']['model_service_info']
                                if 'output' in model_info and 'choices' in model_info['output']:
                                    choices = model_info['output']['choices']
                                    if choices and len(choices) > 0:
                                        choice = choices[0]
                                        if 'message' in choice and 'content' in choice['message']:
                                            content = choice['message']['content']
                                            if content and len(content) > last_content_length:
                                                new_content = content[last_content_length:]
                                                if new_content not in seen_content and len(new_content.strip()) > 0:
                                                    response_content += new_content
                                                    seen_content.add(new_content)
                                                    last_content_length = len(content)
                elif isinstance(response, dict):
                    if 'content' in response:
                        content = response['content']
                        if content and len(content) > last_content_length:
                            new_content = content[last_content_length:]
                            if new_content not in seen_content and len(new_content.strip()) > 0:
                                response_content += new_content
                                seen_content.add(new_content)
                                last_content_length = len(content)
                    elif 'extra' in response and 'model_service_info' in response['extra']:
                        model_info = response['extra']['model_service_info']
                        if 'output' in model_info and 'choices' in model_info['output']:
                            choices = model_info['output']['choices']
                            if choices and len(choices) > 0:
                                choice = choices[0]
                                if 'message' in choice and 'content' in choice['message']:
                                    content = choice['message']['content']
                                    if content and len(content) > last_content_length:
                                        new_content = content[last_content_length:]
                                        if new_content not in seen_content and len(new_content.strip()) > 0:
                                            response_content += new_content
                                            seen_content.add(new_content)
                                            last_content_length = len(content)
                elif hasattr(response, 'content'):
                    content = response.content
                    if content and len(content) > last_content_length:
                        new_content = content[last_content_length:]
                        if new_content not in seen_content and len(new_content.strip()) > 0:
                            response_content += new_content
                            seen_content.add(new_content)
                            last_content_length = len(content)
                else:
                    content = str(response)
                    if content and len(content) > last_content_length:
                        new_content = content[last_content_length:]
                        if new_content not in seen_content and len(new_content.strip()) > 0:
                            response_content += new_content
                            seen_content.add(new_content)
                            last_content_length = len(content)
            
            # å¦‚æœå“åº”å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œè¿”å›å¤‡ç”¨åˆ†æ
            if len(response_content.strip()) < 100:
                return self._generate_fallback_analysis(competitor_data)
            
            # åå¤„ç†ï¼šæ¸…ç†å¯èƒ½çš„é‡å¤å†…å®¹
            cleaned_content = self._clean_duplicate_content(response_content)
            
            return cleaned_content
        except Exception as e:
            return f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
    
    def _clean_duplicate_content(self, content: str) -> str:
        """æ¸…ç†é‡å¤çš„å†…å®¹ï¼Œç‰¹åˆ«æ˜¯é‡å¤çš„æ ‡é¢˜å’Œå¼€å¤´"""
        import re
        
        # æŒ‰è¡Œåˆ†å‰²å†…å®¹
        lines = content.split('\n')
        cleaned_lines = []
        seen_lines = set()
        
        # å®šä¹‰éœ€è¦å»é‡çš„æ¨¡å¼
        duplicate_patterns = [
            r'^#+\s*ç«äº‰å¯¹æ‰‹åˆ†ææŠ¥å‘Š\s*$',
            r'^#+\s*åˆ†ææŠ¥å‘Š\s*$',
            r'^#+\s*å¸‚åœºå®šä½åˆ†æ\s*$',
            r'^#+\s*äº§å“åŠŸèƒ½å¯¹æ¯”\s*$',
            r'^#+\s*å®šä»·ç­–ç•¥åˆ†æ\s*$',
            r'^#+\s*æŠ€æœ¯æ ˆå¯¹æ¯”\s*$',
            r'^#+\s*è¥é”€ç­–ç•¥åˆ†æ\s*$',
            r'^#+\s*ç«äº‰ä¼˜åŠ¿è¯†åˆ«\s*$',
            r'^#+\s*å¸‚åœºæœºä¼šå‘ç°\s*$',
            r'^#+\s*æˆ˜ç•¥å»ºè®®\s*$',
        ]
        
        for line in lines:
            line_stripped = line.strip()
            
            # è·³è¿‡ç©ºè¡Œ
            if not line_stripped:
                cleaned_lines.append(line)
                continue
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯é‡å¤çš„æ ‡é¢˜
            is_duplicate_title = False
            for pattern in duplicate_patterns:
                if re.match(pattern, line_stripped, re.IGNORECASE):
                    if line_stripped in seen_lines:
                        is_duplicate_title = True
                        break
                    seen_lines.add(line_stripped)
                    break
            
            # å¦‚æœä¸æ˜¯é‡å¤æ ‡é¢˜ï¼Œæˆ–è€…è™½ç„¶æ˜¯æ ‡é¢˜ä½†ç¬¬ä¸€æ¬¡å‡ºç°ï¼Œåˆ™ä¿ç•™
            if not is_duplicate_title:
                cleaned_lines.append(line)
        
        # é‡æ–°ç»„åˆå†…å®¹
        cleaned_content = '\n'.join(cleaned_lines)
        
        # è¿›ä¸€æ­¥æ¸…ç†ï¼šç§»é™¤è¿ç»­çš„é‡å¤æ®µè½
        # æŒ‰æ®µè½åˆ†å‰²ï¼ˆä»¥åŒæ¢è¡Œç¬¦ä¸ºåˆ†éš”ç¬¦ï¼‰
        paragraphs = cleaned_content.split('\n\n')
        unique_paragraphs = []
        seen_paragraphs = set()
        
        for paragraph in paragraphs:
            paragraph_stripped = paragraph.strip()
            if paragraph_stripped and paragraph_stripped not in seen_paragraphs:
                # æ£€æŸ¥æ®µè½æ˜¯å¦åŒ…å«é‡å¤çš„æ ‡é¢˜æ¨¡å¼
                has_duplicate_title = False
                for pattern in duplicate_patterns:
                    if re.search(pattern, paragraph_stripped, re.IGNORECASE):
                        # å¦‚æœæ®µè½åŒ…å«é‡å¤æ ‡é¢˜ï¼Œåªä¿ç•™ç¬¬ä¸€æ¬¡å‡ºç°çš„
                        if any(pattern in seen for seen in seen_paragraphs):
                            has_duplicate_title = True
                            break
                
                if not has_duplicate_title:
                    unique_paragraphs.append(paragraph)
                    seen_paragraphs.add(paragraph_stripped)
        
        return '\n\n'.join(unique_paragraphs)
    
    def _generate_fallback_analysis(self, competitor_data: List[Dict]) -> str:
        """ç”Ÿæˆå¤‡ç”¨åˆ†ææŠ¥å‘Š"""
        if not competitor_data:
            return "æ²¡æœ‰ç«äº‰å¯¹æ‰‹æ•°æ®å¯ä¾›åˆ†æ"
        
        analysis = f"""
# ç«äº‰å¯¹æ‰‹åˆ†ææŠ¥å‘Šï¼ˆQwen å¤‡ç”¨ç‰ˆæœ¬ï¼‰

## åˆ†ææ¦‚è§ˆ
æˆåŠŸåˆ†æäº† {len(competitor_data)} ä¸ªç«äº‰å¯¹æ‰‹çš„æ•°æ®ã€‚

## ç«äº‰å¯¹æ‰‹åˆ—è¡¨
"""
        
        for i, competitor in enumerate(competitor_data, 1):
            analysis += f"""
### {i}. {competitor.get('company_name', f'ç«äº‰å¯¹æ‰‹ {i}')}
- **ç½‘ç«™**: {competitor.get('competitor_url', 'N/A')}
- **å®šä»·ç­–ç•¥**: {competitor.get('pricing', 'N/A')[:200]}...
- **å…³é”®åŠŸèƒ½**: {', '.join(competitor.get('key_features', [])[:3]) if competitor.get('key_features') else 'N/A'}
- **æŠ€æœ¯æ ˆ**: {', '.join(competitor.get('tech_stack', [])[:3]) if competitor.get('tech_stack') else 'N/A'}
- **è¥é”€é‡ç‚¹**: {competitor.get('marketing_focus', 'N/A')[:200]}...

"""
        
        analysis += """
## åŸºç¡€åˆ†æå»ºè®®

### 1. å¸‚åœºå®šä½åˆ†æ
- åˆ†æå„ç«äº‰å¯¹æ‰‹çš„å¸‚åœºå®šä½å’Œå·®å¼‚åŒ–ç­–ç•¥
- è¯†åˆ«å¸‚åœºç©ºç™½å’Œæœºä¼š

### 2. äº§å“åŠŸèƒ½å¯¹æ¯”
- å¯¹æ¯”å„ç«äº‰å¯¹æ‰‹çš„æ ¸å¿ƒåŠŸèƒ½å’Œç‰¹æ€§
- å‘ç°åŠŸèƒ½ä¼˜åŠ¿å’Œä¸è¶³

### 3. å®šä»·ç­–ç•¥åˆ†æ
- åˆ†æå®šä»·æ¨¡å¼å’Œç­–ç•¥
- åˆ¶å®šæœ‰ç«äº‰åŠ›çš„å®šä»·æ–¹æ¡ˆ

### 4. æŠ€æœ¯æ ˆå¯¹æ¯”
- åˆ†æå„ç«äº‰å¯¹æ‰‹ä½¿ç”¨çš„æŠ€æœ¯
- è¯„ä¼°æŠ€æœ¯ä¼˜åŠ¿å’ŒåŠ£åŠ¿

### 5. è¥é”€ç­–ç•¥åˆ†æ
- åˆ†æç›®æ ‡å—ä¼—å’Œè¥é”€é‡ç‚¹
- åˆ¶å®šå·®å¼‚åŒ–è¥é”€ç­–ç•¥

## å»ºè®®
1. æ·±å…¥åˆ†æç«äº‰å¯¹æ‰‹çš„ä¼˜åŠ£åŠ¿
2. åˆ¶å®šå·®å¼‚åŒ–ç«äº‰ç­–ç•¥
3. å…³æ³¨å¸‚åœºè¶‹åŠ¿å’Œå®¢æˆ·éœ€æ±‚
4. æŒç»­ç›‘æ§ç«äº‰å¯¹æ‰‹åŠ¨æ€

---
*æ³¨ï¼šæ­¤ä¸ºå¤‡ç”¨åˆ†ææŠ¥å‘Šï¼Œå»ºè®®æ£€æŸ¥Qwen APIé…ç½®ä»¥è·å¾—æ›´æ·±å…¥çš„åˆ†æã€‚*
"""
        
        return analysis

# è·å–ç«äº‰å¯¹æ‰‹ URL çš„å‡½æ•°
def get_competitor_urls(url: str = None, description: str = None) -> List[str]:
    """è·å–ç«äº‰å¯¹æ‰‹ URL åˆ—è¡¨"""
    if not url and not description:
        raise ValueError("è¯·æä¾› URL æˆ–æè¿°")

    if search_engine == "Perplexity AI - Sonar Pro":
        perplexity_url = "https://api.perplexity.ai/chat/completions"
        
        content = "æ‰¾åˆ° 10 ä¸ªä¸å…¬å¸ç›¸ä¼¼çš„ç«äº‰å¯¹æ‰‹å…¬å¸ URLï¼Œ"
        if url and description:
            content += f"URL: {url} å’Œæè¿°: {description}"
        elif url:
            content += f"URL: {url}"
        else:
            content += f"æè¿°: {description}"
        content += "ã€‚åªè¿”å› URLï¼Œä¸è¦å…¶ä»–æ–‡æœ¬ã€‚"

        payload = {
            "model": "sonar-pro",
            "messages": [
                {
                    "role": "system",
                    "content": "ç²¾ç¡®å¹¶åªè¿”å›  10ä¸ªå…¬å¸ URLã€‚"
                },
                {
                    "role": "user",
                    "content": content
                }
            ],
            "max_tokens": 1000,
            "temperature": 0.8,
        }
        
        headers = {
            "Authorization": f"Bearer {st.session_state.perplexity_api_key}",
            "Content-Type": "application/json"
        }

        try:
            response = requests.post(perplexity_url, json=payload, headers=headers)
            response.raise_for_status()
            urls = response.json()['choices'][0]['message']['content'].strip().split('\n')
            return [url.strip() for url in urls if url.strip()]
        except Exception as e:
            st.error(f"ä» Perplexity è·å–ç«äº‰å¯¹æ‰‹ URL æ—¶å‡ºé”™: {str(e)}")
            return []

    else:  # Exa AI
        try:
            if EXA_AVAILABLE:
                exa = Exa(api_key=st.session_state.exa_api_key)
                
                if url:
                    # ä½¿ç”¨ find_similar æŸ¥æ‰¾ç›¸ä¼¼ç½‘ç«™
                    result = exa.find_similar(
                        url=url,
                        num_results=10,
                        exclude_source_domain=True,
                        category="company"
                    )
                else:
                    # ä½¿ç”¨ search æ ¹æ®æè¿°æœç´¢
                    result = exa.search(
                        description,
                        type="neural",
                        category="company",
                        use_autoprompt=True,
                        num_results=10
                    )
                
                # ç¡®ä¿è¿”å›10ä¸ªURLï¼Œå¦‚æœä¸è¶³åˆ™å°è¯•è¡¥å……
                urls = [item.url for item in result.results]
                
                # å¦‚æœç»“æœä¸è¶³10ä¸ªï¼Œå°è¯•ä½¿ç”¨ä¸åŒçš„æœç´¢ç­–ç•¥
                if len(urls) < 10 and description:
                    try:
                        # å°è¯•ä½¿ç”¨ä¸åŒçš„æœç´¢è¯
                        additional_result = exa.search(
                            f"{description} competitors",
                            type="neural",
                            num_results=10 - len(urls)
                        )
                        additional_urls = [item.url for item in additional_result.results]
                        urls.extend(additional_urls)
                    except:
                        pass
                
                # å»é‡å¹¶é™åˆ¶ä¸º10ä¸ª
                unique_urls = list(dict.fromkeys(urls))[:10]
                return unique_urls
            else:
                st.error("Exa åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install exa-py")
                return []
        except Exception as e:
            st.error(f"ä» Exa è·å–ç«äº‰å¯¹æ‰‹ URL æ—¶å‡ºé”™: {str(e)}")
            return []

# ä½¿ç”¨ Firecrawl æå–ç«äº‰å¯¹æ‰‹ä¿¡æ¯
def extract_competitor_info(competitor_url: str) -> Optional[Dict]:
    """ä½¿ç”¨ Firecrawl æå–ç«äº‰å¯¹æ‰‹ä¿¡æ¯"""
    try:
        if not FIRECRAWL_AVAILABLE:
            st.error("Firecrawl åº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install firecrawl-py")
            return None
            
        # åˆå§‹åŒ– FirecrawlApp
        app = FirecrawlApp(api_key=st.session_state.firecrawl_api_key)
        
        # æ·»åŠ é€šé…ç¬¦ä»¥çˆ¬å–å­é¡µé¢
        url_pattern = f"{competitor_url}/*"
        
        # å®šä¹‰æ•°æ®æå–æç¤º
        extraction_prompt = """
        æå–æœ‰å…³å…¬å¸äº§å“çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
        - å…¬å¸åç§°å’ŒåŸºæœ¬ä¿¡æ¯
        - å®šä»·è¯¦æƒ…ã€è®¡åˆ’å’Œå±‚çº§
        - å…³é”®åŠŸèƒ½å’Œä¸»è¦èƒ½åŠ›
        - æŠ€æœ¯æ ˆå’ŒæŠ€æœ¯è¯¦æƒ…
        - è¥é”€é‡ç‚¹å’Œç›®æ ‡å—ä¼—
        - å®¢æˆ·åé¦ˆå’Œæ¨è
        
        åˆ†ææ•´ä¸ªç½‘ç«™å†…å®¹ï¼Œä¸ºæ¯ä¸ªå­—æ®µæä¾›å…¨é¢ä¿¡æ¯ã€‚
        """
        
        # è°ƒç”¨ Firecrawl æå–åŠŸèƒ½
        response = app.extract(
            [url_pattern],
            prompt=extraction_prompt,
            schema=CompetitorDataSchema.model_json_schema()
        )
        
        # å¤„ç† ExtractResponse å¯¹è±¡
        try:
            if hasattr(response, 'success') and response.success:
                if hasattr(response, 'data') and response.data:
                    extracted_info = response.data
                    
                    # åˆ›å»º JSON ç»“æ„
                    competitor_json = {
                        "competitor_url": competitor_url,
                        "company_name": extracted_info.get('company_name', 'N/A') if isinstance(extracted_info, dict) else getattr(extracted_info, 'company_name', 'N/A'),
                        "pricing": extracted_info.get('pricing', 'N/A') if isinstance(extracted_info, dict) else getattr(extracted_info, 'pricing', 'N/A'),
                        "key_features": extracted_info.get('key_features', [])[:5] if isinstance(extracted_info, dict) and extracted_info.get('key_features') else getattr(extracted_info, 'key_features', [])[:5] if hasattr(extracted_info, 'key_features') else ['N/A'],
                        "tech_stack": extracted_info.get('tech_stack', [])[:5] if isinstance(extracted_info, dict) and extracted_info.get('tech_stack') else getattr(extracted_info, 'tech_stack', [])[:5] if hasattr(extracted_info, 'tech_stack') else ['N/A'],
                        "marketing_focus": extracted_info.get('marketing_focus', 'N/A') if isinstance(extracted_info, dict) else getattr(extracted_info, 'marketing_focus', 'N/A'),
                        "customer_feedback": extracted_info.get('customer_feedback', 'N/A') if isinstance(extracted_info, dict) else getattr(extracted_info, 'customer_feedback', 'N/A')
                    }
                    
                    return competitor_json
                else:
                    return None
            else:
                return None
                
        except Exception as response_error:
            return None
            
    except Exception as e:
        st.error(f"ä½¿ç”¨ Firecrawl æå–ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None

# ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
def generate_comparison_report(competitor_data: List[Dict]) -> None:
    """ç”Ÿæˆç«äº‰å¯¹æ‰‹å¯¹æ¯”æŠ¥å‘Š"""
    if not competitor_data:
        st.error("æ²¡æœ‰å¯æ¯”è¾ƒçš„ç«äº‰å¯¹æ‰‹æ•°æ®")
        return
    
    # å‡†å¤‡è¡¨æ ¼æ•°æ®
    table_data = []
    for competitor in competitor_data:
        row = {
            'å…¬å¸': f"{competitor.get('company_name', 'N/A')}",
            'ç½‘ç«™': competitor.get('competitor_url', 'N/A'),
            'å®šä»·': competitor.get('pricing', 'N/A')[:100] + '...' if len(competitor.get('pricing', '')) > 100 else competitor.get('pricing', 'N/A'),
            'å…³é”®åŠŸèƒ½': ', '.join(competitor.get('key_features', [])[:3]) if competitor.get('key_features') else 'N/A',
            'æŠ€æœ¯æ ˆ': ', '.join(competitor.get('tech_stack', [])[:3]) if competitor.get('tech_stack') else 'N/A',
            'è¥é”€é‡ç‚¹': competitor.get('marketing_focus', 'N/A')[:100] + '...' if len(competitor.get('marketing_focus', '')) > 100 else competitor.get('marketing_focus', 'N/A'),
            'å®¢æˆ·åé¦ˆ': competitor.get('customer_feedback', 'N/A')[:100] + '...' if len(competitor.get('customer_feedback', '')) > 100 else competitor.get('customer_feedback', 'N/A')
        }
        table_data.append(row)
    
    # åˆ›å»ºå¹¶æ˜¾ç¤ºè¡¨æ ¼
    df = pd.DataFrame(table_data)
    st.subheader("ğŸ“Š ç«äº‰å¯¹æ‰‹å¯¹æ¯”è¡¨")
    st.markdown("---")
    
    # ä½¿ç”¨æ›´å¥½çš„è¡¨æ ¼æ˜¾ç¤º
    st.dataframe(
        df, 
        use_container_width=True,
        hide_index=True,
        column_config={
            "å…¬å¸": st.column_config.TextColumn("å…¬å¸åç§°", width="medium"),
            "ç½‘ç«™": st.column_config.LinkColumn("ç½‘ç«™é“¾æ¥", width="medium"),
            "å®šä»·": st.column_config.TextColumn("å®šä»·ç­–ç•¥", width="large"),
            "å…³é”®åŠŸèƒ½": st.column_config.TextColumn("å…³é”®åŠŸèƒ½", width="large"),
            "æŠ€æœ¯æ ˆ": st.column_config.TextColumn("æŠ€æœ¯æ ˆ", width="medium"),
            "è¥é”€é‡ç‚¹": st.column_config.TextColumn("è¥é”€é‡ç‚¹", width="large"),
            "å®¢æˆ·åé¦ˆ": st.column_config.TextColumn("å®¢æˆ·åé¦ˆ", width="large")
        }
    )
    
    # æ˜¾ç¤ºè¯¦ç»†æ•°æ®
    st.subheader("ğŸ“‹ è¯¦ç»†ç«äº‰å¯¹æ‰‹ä¿¡æ¯")
    for i, competitor in enumerate(competitor_data, 1):
        with st.expander(f"ğŸ¢ {competitor.get('company_name', f'ç«äº‰å¯¹æ‰‹ {i}')} - è¯¦ç»†ä¿¡æ¯"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**åŸºæœ¬ä¿¡æ¯**")
                st.write(f"**å…¬å¸åç§°**: {competitor.get('company_name', 'N/A')}")
                st.write(f"**ç½‘ç«™**: {competitor.get('competitor_url', 'N/A')}")
                
                st.markdown("**å®šä»·ä¿¡æ¯**")
                st.write(competitor.get('pricing', 'N/A'))
                
                st.markdown("**è¥é”€é‡ç‚¹**")
                st.write(competitor.get('marketing_focus', 'N/A'))
            
            with col2:
                st.markdown("**å…³é”®åŠŸèƒ½**")
                features = competitor.get('key_features', [])
                if features:
                    for feature in features:
                        st.write(f"â€¢ {feature}")
                else:
                    st.write("N/A")
                
                st.markdown("**æŠ€æœ¯æ ˆ**")
                tech_stack = competitor.get('tech_stack', [])
                if tech_stack:
                    for tech in tech_stack:
                        st.write(f"â€¢ {tech}")
                else:
                    st.write("N/A")
                
                st.markdown("**å®¢æˆ·åé¦ˆ**")
                st.write(competitor.get('customer_feedback', 'N/A'))
    
    # æ˜¾ç¤ºåŸå§‹æ•°æ®ï¼ˆå¯é€‰ï¼‰
    with st.expander("ğŸ” æŸ¥çœ‹åŸå§‹JSONæ•°æ®"):
        st.json(competitor_data)

# å¤‡ç”¨åˆ†æå‡½æ•°ï¼ˆä¸ä¾èµ–AIï¼‰
def generate_fallback_analysis(competitor_data: List[Dict]) -> str:
    """ç”Ÿæˆå¤‡ç”¨åˆ†ææŠ¥å‘Šï¼ˆä¸ä¾èµ–AIï¼‰"""
    if not competitor_data:
        return "æ²¡æœ‰ç«äº‰å¯¹æ‰‹æ•°æ®å¯ä¾›åˆ†æ"
    
    analysis = f"""
# ç«äº‰å¯¹æ‰‹åˆ†ææŠ¥å‘Šï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰

## åˆ†ææ¦‚è§ˆ
æˆåŠŸåˆ†æäº† {len(competitor_data)} ä¸ªç«äº‰å¯¹æ‰‹çš„æ•°æ®ã€‚

## ç«äº‰å¯¹æ‰‹åˆ—è¡¨
"""
    
    for i, competitor in enumerate(competitor_data, 1):
        analysis += f"""
### {i}. {competitor.get('company_name', f'ç«äº‰å¯¹æ‰‹ {i}')}
- **ç½‘ç«™**: {competitor.get('competitor_url', 'N/A')}
- **å®šä»·ç­–ç•¥**: {competitor.get('pricing', 'N/A')[:200]}...
- **å…³é”®åŠŸèƒ½**: {', '.join(competitor.get('key_features', [])[:3]) if competitor.get('key_features') else 'N/A'}
- **æŠ€æœ¯æ ˆ**: {', '.join(competitor.get('tech_stack', [])[:3]) if competitor.get('tech_stack') else 'N/A'}
- **è¥é”€é‡ç‚¹**: {competitor.get('marketing_focus', 'N/A')[:200]}...

"""
    
    analysis += """
## åŸºç¡€åˆ†æå»ºè®®

### 1. å¸‚åœºå®šä½åˆ†æ
- åˆ†æå„ç«äº‰å¯¹æ‰‹çš„å¸‚åœºå®šä½å’Œå·®å¼‚åŒ–ç­–ç•¥
- è¯†åˆ«å¸‚åœºç©ºç™½å’Œæœºä¼š

### 2. äº§å“åŠŸèƒ½å¯¹æ¯”
- å¯¹æ¯”å„ç«äº‰å¯¹æ‰‹çš„æ ¸å¿ƒåŠŸèƒ½å’Œç‰¹æ€§
- å‘ç°åŠŸèƒ½ä¼˜åŠ¿å’Œä¸è¶³

### 3. å®šä»·ç­–ç•¥åˆ†æ
- åˆ†æå®šä»·æ¨¡å¼å’Œç­–ç•¥
- åˆ¶å®šæœ‰ç«äº‰åŠ›çš„å®šä»·æ–¹æ¡ˆ

### 4. æŠ€æœ¯æ ˆå¯¹æ¯”
- åˆ†æå„ç«äº‰å¯¹æ‰‹ä½¿ç”¨çš„æŠ€æœ¯
- è¯„ä¼°æŠ€æœ¯ä¼˜åŠ¿å’ŒåŠ£åŠ¿

### 5. è¥é”€ç­–ç•¥åˆ†æ
- åˆ†æç›®æ ‡å—ä¼—å’Œè¥é”€é‡ç‚¹
- åˆ¶å®šå·®å¼‚åŒ–è¥é”€ç­–ç•¥

## å»ºè®®
1. æ·±å…¥åˆ†æç«äº‰å¯¹æ‰‹çš„ä¼˜åŠ£åŠ¿
2. åˆ¶å®šå·®å¼‚åŒ–ç«äº‰ç­–ç•¥
3. å…³æ³¨å¸‚åœºè¶‹åŠ¿å’Œå®¢æˆ·éœ€æ±‚
4. æŒç»­ç›‘æ§ç«äº‰å¯¹æ‰‹åŠ¨æ€

---
*æ³¨ï¼šæ­¤ä¸ºåŸºç¡€åˆ†ææŠ¥å‘Šï¼Œå»ºè®®é…ç½®AIæ¨¡å‹ä»¥è·å¾—æ›´æ·±å…¥çš„åˆ†æã€‚*
"""
    
    return analysis

# ä¸»ç¨‹åºé€»è¾‘
def main():
    """ä¸»ç¨‹åºé€»è¾‘"""
    # æ£€æŸ¥å¿…è¦çš„é…ç½®
    required_configs = []
    
    if not st.session_state.get('model_provider'):
        required_configs.append("AIæ¨¡å‹æä¾›å•†")
    if not st.session_state.get('search_engine'):
        required_configs.append("æœç´¢å¼•æ“")
    if not st.session_state.get('firecrawl_api_key'):
        required_configs.append("Firecrawl API")
    
    if required_configs:
        st.warning(f"è¯·å…ˆé…ç½®ä»¥ä¸‹é€‰é¡¹ï¼š{', '.join(required_configs)}")
        return
    
    # åˆ†ææŒ‰é’®
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        if st.button("ğŸš€ å¼€å§‹åˆ†æç«äº‰å¯¹æ‰‹", type="primary", use_container_width=True):
            if url or description:
                # è·å–ç«äº‰å¯¹æ‰‹ URL
                with st.spinner("æ­£åœ¨æœç´¢ç«äº‰å¯¹æ‰‹..."):
                    competitor_urls = get_competitor_urls(url=url, description=description)
                    st.write(f"æ‰¾åˆ° {len(competitor_urls)} ä¸ªç«äº‰å¯¹æ‰‹ URL")
                
                if not competitor_urls:
                    st.error("æœªæ‰¾åˆ°ç«äº‰å¯¹æ‰‹ URLï¼")
                    st.stop()
                
                # æå–ç«äº‰å¯¹æ‰‹ä¿¡æ¯
                competitor_data = []
                successful_extractions = 0
                failed_extractions = 0
                
                for i, comp_url in enumerate(competitor_urls):
                    with st.spinner(f"æ­£åœ¨ä½¿ç”¨ Firecrawl åˆ†æç«äº‰å¯¹æ‰‹ {i+1}/{len(competitor_urls)}: {comp_url}"):
                        competitor_info = extract_competitor_info(comp_url)
                        
                        if competitor_info is not None:
                            competitor_data.append(competitor_info)
                            successful_extractions += 1
                            st.success(f"âœ“ æˆåŠŸåˆ†æ {comp_url}")
                        else:
                            failed_extractions += 1
                            st.error(f"âœ— åˆ†æå¤±è´¥ {comp_url}")
                
                if competitor_data:
                    st.success(f"æˆåŠŸåˆ†æäº† {successful_extractions}/{len(competitor_urls)} ä¸ªç«äº‰å¯¹æ‰‹ï¼")
                    
                    # ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼
                    with st.spinner("æ­£åœ¨ç”Ÿæˆå¯¹æ¯”è¡¨æ ¼..."):
                        generate_comparison_report(competitor_data)
                    
                    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
                    with st.spinner("æ­£åœ¨ç”Ÿæˆåˆ†ææŠ¥å‘Š..."):
                        try:
                            # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹æä¾›å•†è¿›è¡Œåˆ†æ
                            if st.session_state.model_provider == "openai":
                                if st.session_state.get('openai_api_key'):
                                    analyzer = OpenAIAnalyzer(st.session_state.openai_api_key)
                                    analysis_report = analyzer.analyze_competitors(competitor_data)
                                else:
                                    raise Exception("OpenAI API Key æœªé…ç½®")
                            else:  # qwen
                                if st.session_state.get('dashscope_api_key'):
                                    analyzer = QwenAnalyzer(
                                        st.session_state.dashscope_api_key,
                                        st.session_state.get('qwen_model', 'qwen-max')
                                    )
                                    analysis_report = analyzer.analyze_competitors(competitor_data)
                                else:
                                    raise Exception("DashScope API Key æœªé…ç½®")
                            
                            # æ˜¾ç¤ºåˆ†ææŠ¥å‘Š
                            st.subheader("ğŸ§  ç«äº‰å¯¹æ‰‹æ™ºèƒ½åˆ†ææŠ¥å‘Š")
                            st.markdown("---")
                            
                            # æ£€æŸ¥æŠ¥å‘Šå†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–åŒ…å«é”™è¯¯ä¿¡æ¯
                            if analysis_report and not analysis_report.startswith("åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯") and not analysis_report.startswith("Agent æœªæ­£ç¡®åˆå§‹åŒ–"):
                                # ä½¿ç”¨å®¹å™¨ç¾åŒ–æ˜¾ç¤º
                                with st.container():
                                    st.markdown(analysis_report)
                            else:
                                st.error("AIåˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œæ˜¾ç¤ºåŸºç¡€åˆ†ææŠ¥å‘Š")
                                st.markdown("---")
                                fallback_report = generate_fallback_analysis(competitor_data)
                                st.markdown(fallback_report)
                                
                        except Exception as e:
                            st.error(f"AIåˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                            st.info("æ˜¾ç¤ºåŸºç¡€åˆ†ææŠ¥å‘Šä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆ")
                            st.markdown("---")
                            fallback_report = generate_fallback_analysis(competitor_data)
                            st.markdown(fallback_report)
                    
                    st.success("åˆ†æå®Œæˆï¼")
                else:
                    st.error("æ— æ³•æå–ä»»ä½•ç«äº‰å¯¹æ‰‹æ•°æ®")
            else:
                st.error("è¯·æä¾› URL æˆ–æè¿°")

# è¿è¡Œä¸»ç¨‹åº
if __name__ == "__main__":
    main()

# ä½¿ç”¨è¯´æ˜
with st.expander("ğŸ“– ä½¿ç”¨è¯´æ˜"):
    st.markdown("""
    ## ä½¿ç”¨è¯´æ˜
    
    ### 1. å®‰è£…ä¾èµ–
    ```bash
    # åŸºç¡€ä¾èµ–
    pip install streamlit pandas requests pydantic
    
    # OpenAI æ”¯æŒï¼ˆå¯é€‰ï¼‰
    pip install agno
    
    # Qwen æ”¯æŒï¼ˆå¯é€‰ï¼‰
    pip install -U "qwen-agent[gui,rag,code_interpreter,mcp]"
    
    # ç½‘ç«™çˆ¬å–æ”¯æŒ
    pip install firecrawl-py
    
    # æœç´¢å¼•æ“æ”¯æŒï¼ˆå¯é€‰ï¼‰
    pip install exa-py
    ```
    
    ### 2. è·å– API å¯†é’¥
    - **OpenAI API**: è®¿é—® [OpenAI Platform](https://platform.openai.com/api-keys)
    - **DashScope API**: è®¿é—® [é˜¿é‡Œäº‘ DashScope](https://dashscope.console.aliyun.com/)
    - **Firecrawl API**: è®¿é—® [Firecrawl](https://www.firecrawl.dev/app/api-keys)
    - **Perplexity API** (å¯é€‰): è®¿é—® [Perplexity](https://www.perplexity.ai/settings/api)
    - **Exa API** (å¯é€‰): è®¿é—® [Exa](https://dashboard.exa.ai/api-keys)
    
    ### 2.1 API å¯†é’¥å®‰å…¨ç®¡ç†
    **âš ï¸ é‡è¦å®‰å…¨æç¤ºï¼š**
    - è¯·å‹¿å°†APIå¯†é’¥ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
    - ä¸è¦å°†åŒ…å«APIå¯†é’¥çš„æ–‡ä»¶æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ç³»ç»Ÿ
    - å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶ç®¡ç†APIå¯†é’¥
    - å®šæœŸè½®æ¢APIå¯†é’¥ä»¥ç¡®ä¿å®‰å…¨
    
    ### 3. è¿è¡Œåº”ç”¨
    ```bash
    streamlit run competitor_agent_team_combined.py
    ```
    
    ### 4. åŠŸèƒ½ç‰¹ç‚¹
    - **å¤šæ¨¡å‹æ”¯æŒ**: æ”¯æŒ OpenAI GPT-4 å’Œ Qwen (é€šä¹‰åƒé—®)
    - **æ™ºèƒ½æœç´¢å¼•æ“**: æ”¯æŒ Perplexity AI å’Œ Exa AI
    - **ä¸“ä¸šçˆ¬å–**: ä½¿ç”¨ Firecrawl æå–é«˜è´¨é‡ç½‘ç«™æ•°æ®
    - **æ·±åº¦åˆ†æ**: ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šå’Œå¯¹æ¯”è¡¨æ ¼
    - **é”™è¯¯å¤„ç†**: æ™ºèƒ½é”™è¯¯å¤„ç†å’Œå¤‡ç”¨æ–¹æ¡ˆ
    
    ### 5. æŠ€æœ¯ä¼˜åŠ¿
    - **Firecrawl**: ä¸“ä¸šçš„ç½‘ç«™çˆ¬å–å·¥å…·ï¼Œèƒ½æå–ç»“æ„åŒ–æ•°æ®
    - **å¤šAIæ¨¡å‹**: çµæ´»çš„AIæ¨¡å‹é€‰æ‹©ï¼Œé€‚åº”ä¸åŒéœ€æ±‚
    - **å¤šå¼•æ“æ”¯æŒ**: çµæ´»çš„ç«äº‰å¯¹æ‰‹å‘ç°æœºåˆ¶
    - **å®¹é”™æœºåˆ¶**: å³ä½¿AIåˆ†æå¤±è´¥ï¼Œä¹Ÿèƒ½æä¾›åŸºç¡€åˆ†æ
    
    ### 6. æ³¨æ„äº‹é¡¹
    - ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸
    - API å¯†é’¥éœ€è¦æœ‰æ•ˆ
    - æŸäº›ç½‘ç«™å¯èƒ½æ— æ³•è®¿é—®
    - å»ºè®®ä½¿ç”¨ qwen-max æˆ– gpt-4o æ¨¡å‹è·å¾—æœ€ä½³æ•ˆæœ
    - å¦‚æœAIåˆ†æå¤±è´¥ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨æä¾›åŸºç¡€åˆ†ææŠ¥å‘Š
    """)

# ä¾èµ–æ£€æŸ¥
with st.expander("ğŸ”§ ä¾èµ–æ£€æŸ¥"):
    st.markdown("### ä¾èµ–åº“çŠ¶æ€")
    
    dependencies = [
        ("Streamlit", True, "Webç•Œé¢æ¡†æ¶"),
        ("Pandas", True, "æ•°æ®å¤„ç†"),
        ("Requests", True, "HTTPè¯·æ±‚"),
        ("Pydantic", True, "æ•°æ®éªŒè¯"),
        ("Agno (OpenAI)", AGNO_AVAILABLE, "OpenAIæ¨¡å‹æ”¯æŒ"),
        ("Qwen Agent", QWEN_AVAILABLE, "Qwenæ¨¡å‹æ”¯æŒ"),
        ("Firecrawl", FIRECRAWL_AVAILABLE, "ç½‘ç«™çˆ¬å–"),
        ("Exa", EXA_AVAILABLE, "Exaæœç´¢å¼•æ“æ”¯æŒ")
    ]
    
    for dep_name, available, description in dependencies:
        status = "âœ… å·²å®‰è£…" if available else "âŒ æœªå®‰è£…"
        st.write(f"- **{dep_name}**: {status} - {description}")
    
    if not all([AGNO_AVAILABLE or QWEN_AVAILABLE, FIRECRAWL_AVAILABLE]):
        st.warning("âš ï¸ è¯·å®‰è£…å¿…è¦çš„ä¾èµ–åº“ä»¥è·å¾—å®Œæ•´åŠŸèƒ½")
